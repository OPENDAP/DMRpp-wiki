= Building and Testing DMR++ Documents
OPeNDAP, Inc.
{docdatetime}
:appendix-caption: Exhibit
:toc:
:toclevels: 3
:numbered:
:docinfo: shared
:icons: font
:tabsize: 4
:indent: 4
:source-highlighter: coderay
:coderay-linenums-mode: inline
:prewrap!:
:imagesdir: ./images
:homepage: www.opendap.org
:DMRpp: DMR++
:Miguel Jimenez <mjimenez@opendap.org>:
:James Gallagher <jgallagher@opendap.org>:

//image:logo-hyrax-red.svg[width=300]

== Intended Audience
This document is for people who want to enable access to HDF and netCDF data files stored in Amazon Web Services (AWS) Simple Storage Service (S3) using the OPeNDAP Hyrax data server. It describes how to build the {DMRpp} documents the Hyrax server uses. This document will also be useful to people who want to build {DMRpp} documents for other reasons, such as enabling client-side technology like VirtualiZarr to access/subset data files without using anything other than HTTP.

== Introduction ==

The {DMRpp} is a metadata file that provides a fast and flexible way to access data stored in Amazon Web Services (AWS) Simple Storage Service (S3), or using any other service that supports HTTP Range GET.

The {DMRpp} encodes the location of the data residing in a binary data file/object (e.g., an https://support.hdfgroup.org/documentation/HDF5/latest/[HDF5] file) so that it can be directly accessed, without the need for an intermediate Application Programmer Interface (API) library. The binary data objects may be on a local filesystem, or they may be accessible using HTTP in, for example, an S3 bucket. The Hyrax data server from OPeNDAP can use {DMRpp} files to provide access and subsetting services for data store in S3 without first copying their data files from S3. That is, Hyrax can use the {DMRpp} files to access and subset data 'in place.' This mirrors the behavior of the Hyrax server when used with data files stored on POSIX file systems.

The {DMRpp} is an extension of the Dataset Metadata Response (DMR) from OPeNDAP's DAP4 protocol. For a full description of DAP4 and the DMR object, see the DAP4 protocol, link:https://opendap.github.io/dap4-specification/DAP4.html[Sections 1.5.7–1.5.15]. Briefly, the DMR encodes metadata information about the names, data types, and hierarchical relations of the variables that make up a dataset. The {DMRpp} adds information about the location, size, and other relevant characteristics of those variables. Software can then use this information to read binary data values directly from the dataset's file(s) without using an API library (which generally presupposes that the dataset reside on a POSIX file sytem) or copying the dataset to temporary storage before accessing the data.

// Replaced with the above jhrg 4/24/25
//A DMR is a metadata description of a datafile and is defined in link:https://opendap.github.io/dap4-specification/DAP4.html[the DAP4 protocol, Sections 1.5.7–1.5.15]. The {DMRpp} adds to the _DMR_ of the datafile _extra_ information (thus the+++ ++ +++), such as `byte offsets`, `chunk references`, `compression`, among other relevant information that can be used to get cloud-performant access to datafiles on S3. Hyrax, the OPeNDAP data Server, uses {DMRpp} to efficiently subset data on a local filesystem, in S3, or any other service that supports HTTP 1.1 or newer.

Additional advantages to the {DMRpp} are:

. Enables data providers to take advantage of modern storage technologies for large data without having to reformat huge data collections.

. A {DMRpp} can be programmatically generated by OPeNDAP software for datasets that are made up of HDF5, NetCDF4, HDF4, and HDF4_EOS2 data files.

. Data file integrity is preserved.

NOTE: The OPeNDAP software currently supports HDF5, NetCDF4, HDF4, and HDF4-EOS2. Other formats can be supported, such as Zarr, although that would require additional software development.

[[Diagram]]
.A collection of HDF5 files in an S3 bucket. Each data file has an associated {DMRpp} file, named using the data file name with the suffix ".dmrpp." Because the {DMRpp} uses a URL to reference the data file, it can be stored 'close' to the data or on a different storage system.
image::DMRppS3.png[width=70%, align='center']

////
// I don't think this fits in this document. jhrg 4/24/25
== How Does It Work? ==
The {DMRpp} ingest software reads a data file and builds a document that holds all the file's metadata, the names and types of all the variables along with any other information bound to those variables. This information is stored in a document we call the Dataset Metadata Response (DMR). The {DMRpp} adds some extra information to this regarding where each variable can be found and how to decode those values. The {DMRpp} is simply a special annotated DMR document.

This additional information enables:

* Decoupling the annotated {DMRpp} from the location of the granule file itself.
* Since {DMRpp} files are typically significantly smaller than the source data granules they represent, they can be stored and moved for less expense.
* Reading all the file's metadata in one operation instead of the iterative process that many APIs require.
* If the {DMRpp} contains references to the source granules location on the web, the location of the {DMRpp} file itself does not matter.

Software that understands the {DMRpp} content can directly access the data values held in the source granule file. It can do so without having to retrieve the entire file and work on it locally, even when the file is stored in a Web Object Store like S3.

If the granule file contains multiple variables and only a subset of them are needed, the {DMRpp} enabled software can retrieve just the bytes associated with the specified subset(s) of desired variable(s).
////
== Supported Data Formats ==
The software to build {DMRpp} documents currently works with HDF5, netCDF4, HDF4, and HDF4-EOS2 files.footnote:[The netCDF4 format is a subset of HDF5, so HDF5 tools are used for both.] Other formats like Zarr and netCDF3 are not currently supported by the {DMRpp} software, but support could be added if requested.

// While Zarr is not currently supported by Hyrax as a data source, the Zarr API can be used to read from data described by the {DMRpp}. An external group has developed https://virtualizarr.readthedocs.io/en/latest/[VirtualiZarr] which can parse either {DMRpp} documents and read from data those describe using the Zarr API.

=== The Gory Details ===
The software technologies HDF5, etc., are best thought of as tools that provide a way to define _self-describing_ data files. These types of files are used for scientific data because they can accommodate a wide range of organizational structures for information. In the case of NASA, virtually every one of the more than 8,600 data collections uses a different set of _variables_, so it is reasonable to think of each as a different format. The common aspect across all of them is that a small number of API libraries can be used to read data from each one.

While we aim to provide support for all possible HDF5, HDF4, etc., data files, there are aspects to the _data models_ these API libraries implement that the current {DMRpp} software does n

There are aspects of the _data models_ used by HDF5, etc., that the {DMRpp} software does not yet support. As of April 2025, support for HDF5, as it is used by the NASA Earth Science data collections is close to complete. The best approach to determining if the OPeNDAP {DMRpp} builder software will work for a given collection's HDF5 files is to try it. We suggest picking one or two granules/files and then following the steps outlined here in Section <<sec-build-them>> followed by the testing process described in Section <<sec-test-them>>.

Support for HDF4 and HDF4-EOS2 data files is much newer, and there are probably more edge cases that we will need to work on, but as of April 2025, the same advice applies to these as to the HDF5 case. Try to build the {DMRpp} and then test the result.


==== Is My NetCDF File A Version _3_ or Version _4_ File?
OPeNDAP's {DMRpp} software does not currently support netCDF3 files.footnote:[Not supporting netCDF3 is a shame because it's commonly found in older collections of data and it's one of the simpler data formats.] A complicating factor in building {DMRpp} documents is that it can be hard to tell at a glance if a file is netCDF version 3 or version4. A file with the suffix _.nc4_ is recognized as a _netCDF-4_ file. However, the file suffix _.nc_ can be the commonly used naming convention for both _netCDF-3_ and _netCDF-4_ files.

You can use the `ncdump` command to determine if a _netCDF_ file is either classic _netCDF-3_ or _netCDF-4_. http://www.bic.mni.mcgill.ca/users/sean/Docs/netcdf/guide.txn_79.html[You can learn more in the NetCDF documentation here].

]source, sh]
----
ncdump -k <filename>
----

=== Summary of the {DMRpp} Build Process
[#sec-build-them]
==== Assumptions
You have:

* Docker installed on your computer and at least a basic understanding of its use.
* Data files in a directory on your computer

[NOTE]
In the following, `%` is the terminal prompt. Only some commands produce output, and for those that do, the output is shown below the command. The paths, etc., on your computer will almost certainly be different.

==== Examples
[#sec-examples]
In this section we jump right into some examples without much explanation. This shows the minimum amount of work needed to build the {DMRpp} and sidecar files. See <<sec-cmd-exp>> for details about the gen_dmrpp_side_car command.

Change to the directory that holds your data files and assign an environment variable to the full pathname of that directory. This will streamline some of the later steps in this section. In my case that directory is called `HDF4-dir`, and I used the environment variable 'DATA.'

[source,sh]
----
% cd HDF4-dir
% export DATA=$(pwd)
% echo $DATA
/Users/jimg/src/opendap/hyrax_git/HDF4-dir
----

Run the Docker container. The docker run command returns the Container ID (a long hexadecimal string) when the `-d` (run a detached container) is used. The `--name` option sets _hyrax_ as the name of the container which will be used in later commands. Running the container this way enables us to use both build {DMRpp} documents and test them.

[source,sh]
----
% docker run -d -h hyrax -p 8080:8080 -v $DATA:/usr/share/hyrax --name=hyrax opendap/hyrax:1.17.1-126
9c88a0d4abe55f17802afd81150280073314f3940b9cd4973ea60dbc43f733a9
----

Here are the files on my computer in the directory assigned to $DATA

[source,sh]
----
% ls
3B42.19980101.00.7.HDF
3B42.19980101.03.7.HDF
3B42.19980101.06.7.HDF
3B42.19980101.09.7.HDF
3B42.20130111.06.7.HDF
3B42.20130111.09.7.HDF
AIRS.2009.01.01.L3.RetStd_IR001.v7.0.3.0.G20160024306.hdf
AIRS.2009.01.02.L3.RetStd_IR001.v7.0.3.0.G20160024358.hdf
AIRS.2009.01.03.L3.RetStd_IR001.v7.0.3.0.G20160024538.hdf
AMSR_E_L2_Land_V09_200206191023_D.hdf
AMSR_E_L2_Land_V09_200206191112_A.hdf
AMSR_E_L3_SeaIce25km_V15_20020601.hdf
MCD12Q1.A2022001.h10v06.061.2023243073808.hdf
MCD19A1.A2024025.h10v06.061.2024027100206.hdf
MOD10A1F.A2024025.h01v08.061.2024027134335.hdf
MOD10A1F.A2024025.h01v09.061.2024027130238.hdf
MOD10A1F.A2024025.h01v10.061.2024027131939.hdf
MOD11A1.A2024025.h10v06.061.2024028004317.hdf
----

To build a {DMRpp} for the first AIRS file (`AIRS.2009.01.01.L3.RetStd_IR001.v7.0.3.0.G20160024306.hdf`) we can run the gen_dmrpp_side_car command using exec using the file's name.

[source,sh]
----
% docker exec -it -w /usr/share/hyrax hyrax gen_dmrpp_side_car -i AIRS.2009.01.01.L3.RetStd_IR001.v7.0.3.0.G20160024306.hdf -H -U
% ls
3B42.19980101.00.7.HDF
3B42.19980101.03.7.HDF
3B42.19980101.06.7.HDF
3B42.19980101.09.7.HDF
3B42.20130111.06.7.HDF
3B42.20130111.09.7.HDF
AIRS.2009.01.01.L3.RetStd_IR001.v7.0.3.0.G20160024306.hdf
AIRS.2009.01.01.L3.RetStd_IR001.v7.0.3.0.G20160024306.hdf.dmrpp
AIRS.2009.01.02.L3.RetStd_IR001.v7.0.3.0.G20160024358.hdf
...
----

Another example, this time both the {DMRpp} and a sidecar _missing data_ file (`3B42.19980101.00.7.HDF_mvs.h5`) were built. Even though the input data file was an HDF4 file, the missing data file uses HDF5 to store the values. For this example, we should the sizes of the input data file and the smaller {DMRpp} and missing data file, which together are only 2% of the data file's size.

[#ex-missing]
[source,sh]
----
% docker exec -it -w /usr/share/hyrax hyrax gen_dmrpp_side_car -i 3B42.19980101.00.7.HDF -H -U
% ls -l
total 1245840
-rw-r--r--@ 1 jimg  staff     774595 Aug 22  2024 3B42.19980101.00.7.HDF
-rw-r--r--  1 jimg  staff       6514 Apr 21 22:42 3B42.19980101.00.7.HDF.dmrpp
-rw-r--r--  1 jimg  staff       8075 Apr 21 22:42 3B42.19980101.00.7.HDF_mvs.h5
-rw-r--r--@ 1 jimg  staff     765742 Aug 22  2024 3B42.19980101.03.7.HDF
...
----

==== Explanation of the `gen_dmrpp_side_car` Command Options
[#sec-cmd-exp]
The gen_dmrpp_side_car command takes a few options that control how it builds {DMRpp} and sidecar files. The `-i` option is used to name the _input data file_. This data file should be found in the directory where the command is being run, or one of its child directories. In the latter case, the relative pathname to the file should be used. This option is required.

The `-H` option tells the command that the input file is an HDF4 or HDF4-EOS2 data file. If the `-H` option is not used, then the data file is assumed to be either HDF5 or netCDF4.

The `-c` and `-D` options are used to control behavior of the command. The `-c` option results in {DMRpp} and sidecar files that follow the Climate Forecast (CF) conventions. Using this option provides a {DMRpp} that mimics the behavior of the Hyrax server when it is used to service data stored on POSIX file systems with the _EnableCF_ option turned on. This organizes the presentation of the variables to follow CF and flattens the internal hierarchy of the data files, hiding any _Groups_.

The `-D` option will disable the build of a sidecar file, even when one would normally be required.

The `-u/U` and `-s/S` options control how URLs are represented in the {DMRpp} document. It is possible to build a {DMRpp} before the location of the data file in S3, for example, is known. In this case, the URL that references the data file will be represented by a 'template' value and substituted into the {DMRpp} _when the document is used_, nominally by the Hyrax service at runtime (although other software can also do this substitution - it is a simple text replacement). The same can be said for the URL that references the sidecar geo-referencing data file. The Hyrax service _assumes_ that the data file URL can be determined by removing the suffix `.dmrpp` from the {DMRpp} URL. Similarly, it assumes that the sidecar data file URL can be found by replacing the `.dmrpp` suffix with `_mvs.h5`. See <<ex-missing>>. Note that these options can be used to provide real values for data file and sidecar data URls. In that case, the given values will be used in the {DMRpp} instead of the template values. No run-time substitution of the URLs will be performed.

==== Explanation of the `docker run` Command Options
[#sec-docker-exp]
In the Section <<sec-examples>> we used one docker command to start a container and then a second docker command to run the {DMRpp} builder inside that container. Here is an explanation of those commands in more detail. First, the container is started on the host computer.

[source,sh]
----
% docker run -d -h hyrax -p 8080:8080 -v $DATA:/usr/share/hyrax --name=hyrax opendap/hyrax:1.17.1-126
9c88a0d4abe55f17802afd81150280073314f3940b9cd4973ea60dbc43f733a9
----

The `docker run -d ...` command will run the Hyrax container on your computer (called the _host_ computer) in _detached_ mode. The Hyrax container includes both the complete Hyrax service and the `gen_dmrpp_side_car` command. Later this server will be used to test the {DMRpp} documents that are built.

The volume mount, from `$HDF4_DIR` to `/usr/share/hyrax` mounts the current directory of the host computer running the container to the directory _/usr/share/hyrax_ inside the container. That directory is the root of the Hyrax server's data tree. This means that the data files in the `DATA` directory will be accessible by the server running in the container without any other configuration.

Complete option summary:
[horizontal]
-d, --detach:: Run container in the background and print container ID
-h, --hostname:: Set the container's host name
-p, --publish:: Publish a container's port(s) to the Docker host
-v, --volume:: Mount a volume so that the container can use files on the Docker host
--name:: Assign a name to the container; this name can be used in later Docker commands

Once running, the container is used to run the command that will build the {DMRpp} document.

[source, sh]
----
% docker exec -it -w /usr/share/hyrax hyrax gen_dmrpp_side_car -i 3B42.19980101.00.7.HDF -H -U
----

The command that built the {DMRpp} (and sidecar) file really consists of _two commands_. The first is `docker exec -it -w /usr/share/hyrax hyrax` which instructs docker to _execute_ a program in the running container named _hyrax_ and do so by first changing to the directory _/usr/share/hyrax_ in that container. By using the `-w` option we are able to run the gen_dmrpp_side_car command in the directory within the container where data appear.

The second command instructs the docker container to run `gen_dmrpp_side_car` using the arguments `-i 3B42.19980101.00.7.HDF -H -U` which mean use the file _3B42.19980101.00.7.HDF_ as the input data file, assume it is an HDF4 file and use the template name for the sidecar data file.

Complete option summary for the `docker exec` command:
[horizontal]
-i, --interactive:: Set the working directory inside the container
-t, --tty:: Allocate a pseudo-terminal
-w, --workdir:: Set the working directory inside the container

[NOTE]
If you want to use a specific container version, substitute the version info for _1.17.1-126_ in the above commands. For example, to use the latest build of the container, use _snapshot_ instead of the version number.

==== Useful Docker Commands
A useful docker command, `ps`, provides a way to see which docker containers are running.

[source,sh]
----
% docker ps
----
or make a command alais for a more compact listing than the default output of `docker ps`
[source,sh]
----
% alias d-ps='docker ps --format "table {{.ID}}\t{{.Names}}\t{{.Status}}\t{{.Image}}"'
----
This will show a somewhat easier-to-read bit of information about all the running Docker container on your host:
[source,sh]
----
% d-ps

CCONTAINER ID   NAMES     STATUS          IMAGE
82074fe6ccfe    hyrax     Up 13 minutes   opendap/hyrax:1.17.1-126
----
If you want to stop the container, use
[source,sh]
----
% docker rm -f hyrax
----

== Testing {DMRpp} Containers Using the Builtin Hyrax Server
[#sec-test-them]
One of the more confounding things about serving data with {DMRpp} documents is that it requires a data server, or some software component, that can interpret the documents. Instead of the data being directly available, the {DMRpp} sits between the software and the data. In this section we show how to test a {DMRpp} document that using the Hyrax server running in the container used to build the {DMRpp} document. To do this, we will build the {DMRpp} with _file URLs_ for the data and sidecar files instead of _HTTP URLs_ or the _template values_ that the command would normally use.

----
% docker exec -it -w /usr/share/hyrax hyrax gen_dmrpp_side_car -i 3B42.20130111.09.7.HDF -H -u 'file:///usr/share/hyrax/3B42.20130111.09.7.HDF'
----

Copy that pattern for whatever file you use. From the `/usr/share/hyrax` directory, you pass _get_dmrpp_h4_ the name of the file (because it's local to the current directory) using the `-i` option. The `-u` option tells the command to embed the URL that follows it in the {DMRpp}. I've used a _file://_  URL to the file _/usr/share/hyrax/3B42.19980101.00.7.HDF_.

NOTE: In the URL above, three slashes follow the colon: two from the way a URL names a protocol and one because the pathname starts at the root directory.

Let's look at how the _hyrax_ service will treat that data file using the {DMRpp}. In a browser, go to  http://localhost:8080/opendap/[http://localhost:8080/opendap/]. The _hyrax_ container must be started using the `docker run` command for this to work (Section <<sec-examples>>).

.Hyrax Catalog view of all files available.
image::Hyrax-including-new-DMRpp.png[width=650, height=400]

NOTE: The server caches data catalog information for 5 minutes (although this can be configured) so new items (e.g., {DMRpp} documents) may not show up right away. To force the display of a {DMRpp} that you just created, click on the source data file name and edit the URL so that the suffix `.dmr.html` is replaced by `.dmrpp/dmr` .

Click on your equivalent of the `3B42.20130111.09.7.HDF` link, subset, download, and open in Panoply or the equivalent.

.Page view of the DAP _Data Request Form_ for subsetting the dataset.
image::Hyrax-subsetting.png[width=650, height=400]

Below is a comparison of the same underlying data, the left window shows the data returned using the {DMRpp}, the right shows the data read directly from the file using the server's builtin HDF4 reader.

.Comparison of responses from a {DMRpp} and the native file handler.
image::Data-comparison.png[width=650, height=400]

== Serving Data Using {DMRpp} Files ==

There are three fundamental deployment scenarios for using {DMRpp} files to serve data with the Hyrax data server.

This can be simple categorized as follows:
The {DMRpp} file(s) are XML files that contain a root `dap4:Dataset` element with a `dmrpp:href` attribute whose value is one of:

. A http(s):// URL referencing to the underlying granule files via http.

. A file:// URL that references the granule file on the local filesystem in a location that is inside the BES' data root tree.

. The template string `OPeNDAP_DMRpp_DATA_ACCESS_URL`

Each will be discussed in turn below.

NOTE: By default, Hyrax will automatically associate files whose name ends with ".dmrpp" with the *{DMRpp}* handler.


=== Using {DMRpp} with http(s) URLs ===

If the {DMRpp} files that you wish to serve contain `dmrpp:href` attributes whose values are http(s) URLs then there are 2+1 steps to serve the data:

. Place the {DMRpp} files on the local disk inside the directory tree identified by the `BES.Catalog.catalog.RootDirectory` in the BES configuration.
. Ensure that the Hyrax `AllowedHosts` list is configured to allow Hyrax to access those target URLs. This can be accomplished by adding new regex records to the `AllowedHosts` list in `/etc/bes/site.conf`, creating that file as need be.
. If the data URLs require authentication to access then you'll need to configure Hyrax for that too.


=== Using {DMRpp} with file URLs ===

Using {DMRpp} files with locally held files can be useful for verifying that {DMRpp} functionality is working without relying on network access that may have data rate limits, authenticated access configuration, or security access constraints. Additionally, in many cases the {DMRpp} access to the locally held data may be significantly faster than through the native `netcdf-4/HDF5` data handlers.

In order to use {DMRpp} files that contain file:// URLs:
. Place the {DMRpp} files on the local disk inside the directory tree identified by the `BES.Catalog.catalog.RootDirectory` in the BES configuration.
. Ensure that the {DMRpp} files contain only file:// URLs that refer to data granule files that are inside the directory tree identified by the `BES.Catalog.catalog.RootDirectory` in the BES configuration.

Note: For Hyrax, a correctly formatted file URL must start with the protocol `file://` followed by the full qualified path to the data granule, for example: 

`/usr/share/hyrax/ghrsst/some_granule.h5`

so that the completed URL will have three slashes after the first colon:

`file:///usr/share/hyrax/ghrsst/some_granule.h5`

=== Using {DMRpp} with the template string (NASA). ===

Another way to serve {DMRpp} files with Hyrax is to build the {DMRpp} files *without* valid URLs but with a template string that is replaced at runtime. If no target URL is supplied to _get_drmpp_ at the time that the {DMRpp} is generated the template string: `*OPeNDAP_DMRpp_DATA_ACCESS_URL*` will be added to the file in place of the URL. The at runtime it can be replaced with the correct value.

Currently, the only implementation of this is Hyrax's NGAP service which, when deployed in the NASA NGAP cloud, will accept "restified path" URLs that are defined as having a URL path component with two mandatory and one optional parameters:

----------------------------------------------------
 MANDATORY: "/collections/UMM-C:{concept-id}"
 OPTIONAL:  "/UMM-C:{ShortName} '.' UMM-C:{Version}"
 MANDATORY: "/granules/UMM-G:{GranuleUR}"
----------------------------------------------------

*Example:* https://opendap.earthdata.nasa.gov/collections/C1443727145-LAADS/MOD08_D3.v6.1/granules/MOD08_D3.A2020308.061.2020309092644.hdf.nc

When encountering this type of URL Hyrax will decompose it and use the content to formulate a query to the NASA CMR in order to retrieve the data access URL for the granule and for the {DMRpp} file. It then retrieves the {DMRpp} file and injects the data URL so that data access can proceed as described above.


More on the Restified Path can be found https://wiki.earthdata.nasa.gov/display/DUTRAIN/Feature+analysis%3A+Restified+URL+for+OPENDAP+Data+Access[here] ([.underline]#NOTE: You need the right permissions access the previous URL#).

== Recipe: Building and testing {DMRpp} files ==
There are two recipes shown here, the first using a Hyrax docker container and a second using the container that is part of the NASA EOSDIS Cumulus task.

*_Prerequisites_*:

- The Docker daemon running on a system that also supports a shell (the examples use bash in this section).

=== Recipe: Building {DMRpp} files using a Hyrax docker container ===

. Acquire representative granule files for the collection you wish to import. Put them on the system that is running the Docker daemon. For this recipe we will assume that these files have been placed in the directory:

	/tmp/dmrpp

. Get the most up-to-date Hyrax docker image:

	docker pull opendap/hyrax:snapshot

. Start the docker container, mounting your data directory on to the docker image at `/usr/share/hyrax`:

	docker run -d -h hyrax -p 8080:8080 --volume /tmp/dmrpp:/usr/share/hyrax --name=hyrax opendap/hyrax:snapshot

. Get a first view of your data using `get_dmrpp` with its default configuration.

.. If you want you can build a {DMRpp} for an example "input_file" using a docker exec command:

	docker exec -it hyrax get_dmrpp -b /usr/share/hyrax -o /usr/share/hyrax/input_file.dmrpp -u "file:///usr/share/hyrax/input_file" "input_file"

.. Or if you want more scripting flexibility you can log in to the docker container to do the same:

... Login to the docker container:

	docker exec -it hyrax /bin/bash

... Change working dir to data dir: 

	cd /usr/share/hyrax

... Set the data directory to the current one (`-b $(pwd)`) and set the data URL (`-u`) to the fully qualified path to the input file.

	get_dmrpp -b $(pwd) -o foo.dmrpp -u "file://"$(pwd)"/your_test_file" "your_test_file"

NOTE: Now that you have made a dmr++ file, use the running Hyrax server to view and test it by pointing your browser at: http://localhost:8080/opendap/

[start=5]
. You can also batch process all of your test granules, if you want to go that route. The following script assumes your source data files end with '.h5'.

NOTE: The resulting *{DMRpp}* files should contain the correct file:// URLs and be correctly located so that they may be tested with the Hyrax service running in the docker instance.

------------------------------------------------------------------------------------
#!/bin/bash
# This script will write each output file as a sidecar file into 
# the same directory as its associated input granule data file.

# The target directory to search for data files 
target_dir=/usr/share/hyrax
echo "target_dir: $target_dir";

# Search the target_dir for names matching the regex \*.h5 
for infile in `find "$target_dir" -name \*.h5`
do
    echo " Processing: $infile"

    infile_base=`basename "${infile}"`
    echo "infile_base: $infile_base"

    bes_dir=`dirname "${infile}"`
    echo "    bes_dir: $bes_dir"

    outfile="$infile.dmrpp"
    echo "     Output: $outfile"

    get_dmrpp -b "$bes_dir" -o "$outfile" -u "file://$infile" "$infile_base"
done
------------------------------------------------------------------------------------

TIP: Remember that you can use the Hyrax server that is running in the docker container to view and test the {DMRpp} files you just created by pointing your browser at: http://localhost:8080/opendap/


=== Testing and qualifying {DMRpp} files ===
In the previous section/step we created some initial {DMRpp} files using the default configuration. It is crucial to make sure that they provide the representation of the data that you and your users are expecting, and that they will work correctly with the Hyrax server. (See the following sections for details). If the generated {DMRpp} files do not match expectations then the default configuration of the `get_dmrpp` may need to be amended using the `-s` parameter.
If the data are currently being served by your DAAC's on-prem team this is where understanding exactly what the localizations made to the configurations of the on-prem Hyrax instances deployed for the collection is important. These localization will probably need to be injected into `get_drmpp` in order to produce the correct data representation in the {DMRpp} files.


=== Flattening Groups ===
By default `get_dmrpp` will preserve and show group hierarchies. If this is not desired, say for CF-1.0 compatibility, then you can change this by creating a small amendment to `get_dmrpp`'s default configuration. 

First create the amending configuration file:

	echo "H5.EnableCF=true" > site.conf

Then, change the invocation of `get_dmrpp` in the above example by adding the `-s` switch:

	get_dmrpp -s site.conf -b `pwd` -o "$dmrpp_file" -u "file://"`pwd`"/$file" "$file"

And re-run the {DMRpp} production as shown above.



=== DAP representations ===
We have test and assurance procedures for DAP4 and DAP2 protocols below. Both are important. For legacy datasets the DAP2 request API is widely used by an existing client base and should continue to be supported. Since DAP4 subsumes DAP2 (but with somewhat different API semantics) It should be checked for legacy datasets as well. For more modern datasets that content DAP4 types such as Int64 that are not part of the DAP2 specification or implementations we will need to rely on eliding the instances of unmapped types, or return an error when this is encountered.


------------------------------------------------------
# Test Constants:
GRANULE_FILE="some_name.h5"
# Granule URL
gf_url="http://localhost:8080/opendap/$GRANULE_FILE"
------------------------------------------------------



==== Inspect the {DMRpp} files ====

Do the {DMRpp} files have the expected `dmrpp:href` URL(s)?

	head -2 "$GRANULE_FILE.dmrpp"

==== Check DAP4 DMR Response ====
Inspect `$gf_url.dmrpp.dmr`

. Get the document, save as `foo.dmr`:

	curl -L -o foo.dmr "$gf_url.dmr"

. Is each variable's data type correct and as expected?
. Are the associated dimensions correct?


==== DAP4 Check binary data response ====

For a particular granule named GRANULE_FILE and a particular variable, named VARIABLE_NAME (Where VARIABLE_NAME is a https://opendap.github.io/dap4-specification/DAP4.html#_fully_qualified_names[full qualified DAP4 name]):

    curl -L -o dap4_subset_file "$gf_url.dap?dap4.ce=VARIABLE_NAME"
    curl -L -o dap4_subset_dmrpp "$gf_url.dmrpp.dap?dap4.ce=VARIABLE_NAME"
    cmp dap4_subset_file dap4_subset_dmrpp


==== DAP4 UI test ====

View and exercise the DAP4 Data Request Form `$gf_url.dmr.html` with a browser.

==== DAP2 Check DDS Response ====

. Inspect `$gf_url.dds`
.. Is each variable's data type correct and as expected?
.. Are the associated dimensions correct?
. Compare {DMRpp} DDS with granule file DDS -
For a particular granule named GRANULE_FILE and a particular variable named VARIABLE_NAME (Where VARIABLE_NAME is a https://zenodo.org/records/10794666[DAP2 name]):

    curl -L -o dap2_dds_file "$gf_url.dds"
    curl -L -o dap2_dds_dmrpp "$gf_url.dds"
    cmp dap2_dds_file dap2_dds_dmrpp


==== DAP2 Check binary data response ====

For a particular granule named GRANULE_FILE and a particular variable, VARIABLE_NAME (Where VARIABLE_NAME is a https://zenodo.org/records/10794666[DAP2 name]):


    curl -L -o dap2_subset_file "$gf_url.dods?VARIABLE_NAME"
    curl -L -o dap2_subset_dmrpp "$gf_url.dmrpp.dods?VARIABLE_NAME"
    cmp dap2_subset_file dap2_subset_dmrpp

NOTE: One might consider doing this with two or more variables. 

==== DAP2 UI Test ====

. View and exercise the DAP2 Data Request Form located here: `$gf_url.html`.
. Try it in Panoply! 
.. Open Panoply.
.. From the File menu select *Open Remote Dataset*...
.. Paste the `$gf_url.html` into the resulting dialog box.

[appendix]
=== HDF5 ===
// TODO Rewrite this since, at this point all known NASA HDF5 files are supported. 4/22/25
The HDF5 data format is quite complex, and many of the options and edge cases are not currently supported by the {DMRpp} software.

These limitations and how to quickly evaluate a HDF5 or netCDF4 file for use with the {DMRpp} software are explained below.

==== HDF5 filters ====

The HDF5 format has several filter/compression options used for storing data values.
The {DMRpp} software currently supports data that use the  H5Z_FILTER_DEFLATE, H5Z_FILTER_SHUFFLE, and H5Z_FILTER_FLETCHER32 filters.
https://support.hdfgroup.org/documentation/HDF5/latest/group___h5_z.html[You can find more on HDF5 filters here.]

==== HDF5 storage layouts ====

The HDF5 format also uses a number of "storage layouts" that describe various structural organizations of the data values associated with a variable in the granule file.
The {DMRpp} software currently supports data that use the  H5D_COMPACT, H5D_CHUNKED, and H5D_CONTIGUOUS storage layouts. These are all the storage layouts defined by the HDF5 library, but others can be added.
https://support.hdfgroup.org/releases/HDF5/v1_16/v1_16_0/documentation/doxygen/_l_b_dset_layout.html[You can find more on HDF5 storage layouts here.]

==== Is my HDF5 or netCDF4 file suitable for {DMRpp}?
To get a human-readable assessment of the file that will show the storage layouts, chunking structure, and the filters needed for each variable (aka DATASET in the _HDF5_ vocabulary), use the https://support.hdfgroup.org/ftp/HDF5/documentation/doc1.6/Tools.html#Tools-Dump[h5dump] command line program.

.h5dump example output
[source,sh]
----
$ h5dump -H -p chunked_gzipped_fourD.h5
HDF5 "chunked_gzipped_fourD.h5" {
	GROUP "/" {
		DATASET "d_16_gzipped_chunks" {
			DATATYPE  H5T_IEEE_F32LE
			DATASPACE  SIMPLE { ( 40, 40, 40, 40 ) / ( 40, 40, 40, 40 ) }
			STORAGE_LAYOUT {
				CHUNKED ( 20, 20, 20, 20 )
				SIZE 2863311 (3.576:1 COMPRESSION)
			}
			FILTERS {
				COMPRESSION DEFLATE { LEVEL 6 }
			}
			FILLVALUE {
				FILL_TIME H5D_FILL_TIME_ALLOC
				VALUE  H5D_FILL_VALUE_DEFAULT
			}
			ALLOCATION_TIME {
				H5D_ALLOC_TIME_INCR
			}
		}
	}
}
----

=== HDF4 and HDF4-EOS2 ===
The internal data storage layout in an HDF4 file is more complex than that in an HDF5 file, and we're focusing on complete support for those features used by NASA. In addition, we also support HDF4-EOS2, data files that should be read with the HDF4-EOS2 library. The main reason of using the HDF-EOS2 API is to retrieve the values for the Domain variables such as  Latitude and Longitude. Our support handles the HDF4-EOS Grid data type and uses {DMRpp} to retrieve  the Latitude and Longitude values appear as users expect. Dmrpp can handle hDF-EOS2 swath. However, for some HDF-EOS2 MODIS swath (level 1B etc.), currently users need to find the corresponding HDF-EOS2 files (MODIS level 3 products) that store the actual latitude and longitude values for each data point. The {Dmrpp} module doesn't support  automatic merging of the latitude and longitude of such HDF-EOS2 swath data.

== Building {DMRpp} Documents
[NOTE]
The `gen_dmrpp_side_car` is a command line tool for building {DMRpp} documents introduced in March 2025 and is available only using the Hyrax Docker container version _1.17.1-126_ or later.

The `gen_dmrpp_side_car` command, introduced in March 2025, can be used to build {DMRpp} documents for HDF5, netCDF4, HDF4, and HDF-EOS2 data files. This command will also build _sidecar_ data files when needed that provide additional information that simplifies using the data in these files. For many of the NASA data collections, geo-referencing data were not included in the data files to reduce file size. The gen_dmrpp_side_car command will store the 'missing' geo-referencing data in a sidecar file and build a {DMRpp} document that automatically referencing that sidecar file, providing seamless access to those geo-referencing values.

[appendix]
== Using the New Builder Command
// From Kent in April 2025. jhrg 4/25/25

=== HDF4
To generate a dmrpp file for the HDF4 file hdf4.hdf. Do the following:
[source,sh]
----
gen_dmrpp_side_car -I hdf4.hdf -H -U
----
If a sidecar file is generated, the sidecar file is always named after the original HDF4 file plus `_mvs.h5`. For example, `hdf4.hdf_mvs.h5.`

NOTE: Note: `-H -U` are critical and cannot be omitted.

=== HDF5
To generate a dmrpp file for the HDF5 file `HDF5.h5`. Do the following:
[source,sh]
----
gen_dmrpp_side_car -i HDF5.h5  -U
----


