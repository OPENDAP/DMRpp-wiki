:toc:
:toclevels: 3
:numbered:
:docinfo: shared
:icons: font
:tabsize: 4
:indent: 4
:source-highlighter: coderay
:coderay-linenums-mode: inline
:prewrap!:
:imagesdir: ./images
:homepage: www.opendap.org
:DMRpp: DMR++
:Miguel Jimenez <mjimenez@opendap.org>:
:James Gallagher <jgallagher@opendap.org>:

== Building {DMRpp} files for HDF5/NetCDF4 with _get_dmrpp_ ==



The application that builds the {DMRpp} files is a command line tool called _get_dmrpp_. It in turn utilizes other executables such as _build_dmrpp_, _reduce_mdf_, _merge_dmrpp_ (which rely in turn on the _HDF5_handler_ and the HDF5 library), along with a number of UNIX shell commands.

All of these components are install with each recent version of the Hyrax Data Server

You can see the _get_dmrpp_ usage statement with the command:

------------
get_dmrpp -h
------------


=== Using _get_dmrpp_ ===

The way that _get_dmrpp_ is invoked controls the way that the data are ultimately represented in the resulting {DMRpp} file(s).

The _get_dmrpp_ application utilizes software from the Hyrax data server to produce the base DMR document which is used to construct the {DMRpp} file.

The Hyrax server has a long list of configuration options, several of which can substantially alter the structural and semantic representation of the dataset as seen in the {DMRpp} files generated using these options.

=== Command line options ===

The command line switches provide a way to control the output of the tool. In addition to common options like verbose output or testing modes, the tool provides options to build extra (aka 'sidecar') data files that hold information needed for CF compliance if the original HDF5 data files lack that information (see the ''missing data'' section ). In addition, it is often desirable to build {DMRpp} files before the source data files are uploaded to a cloud store like S3. In this case, the URL to the data may not be known when the {DMRpp} is built. We support this by using placeholder/template strings in the ''dmr++'' and which can then be replaced with the URL at runtime, when the {DMRpp} file is evaluated. See the '-u' and '-p' options below.


==== Inputs ====


*-b* ::
The fully qualified path to the top level data directory. Data files read by _get_dmrpp_ must be in the directory tree rooted at this location and their names expressed as a path relative to this location. The value may not be set to `/` , or `/etc`. The default value is `/tmp` if a value is not provided. All the data files to be processed must be in this directory or one of its subdirectories. If _get_dmrpp_ is being executed from same directory as the data then `-b `pwd`` or `-b .` works as well.

*-u* ::
This option is used to specify the location of the binary data object. It’s value must be a http, https, or a `file://` URL. This URL will be injected into the {DMRpp} when it is constructed. If option `-u` is not used; then the template string `OPeNDAP_DMRpp_DATA_ACCESS_URL` will be used and the {DMRpp} will substitute a value at runtime.

*-c* ::
The path to an alternate bes configuration file to use.

*-s* ::
The path to an optional addendum configuration file which will be appended to the default BES configuration. Much like the `site.conf` file works for the full server deployment it will be loaded last and the settings there-in will have an override effect on the default configuration.


==== Output ====

*-o* ::
The name of the file to create.

==== Verbose Output Modes ====

*-h* ::
Show help/usage page.
*-v* ::
verbose mode, prints the intermediate DMR.
*-V* ::
Very verbose mode, prints the DMR, the command, and the configuration file used to build the DMR.
*-D* ::
Just print the DMR that will be used to build the {DMRpp}.
*-X* ::
Do not remove temporary files. May be used independently of the `-v` and/or `-V` options.


==== Tests ====

*-T* ::
Run ALL hyrax tests on the resulting {DMRpp} file and compare the responses the ones generated by the source HDF5 file.
*-I* ::
Run hyrax inventory tests on the resulting {DMRpp} file and compare the responses the ones generated by the source HDF5 file.
*-F* ::
Run hyrax value probe tests on the resulting {DMRpp} file and compare the responses the ones generated by the source HDF5 file.

==== Missing Data Creation ====


*-M* ::
Build a 'sidecar' file that holds missing information needed for CF compliance (e.g., Latitude, Longitude and Time coordinate data).
*-p* ::
Provide the URL for the Missing data sidecar file. If this is not given (but -M is), then a template value is used in the {DMRpp} file and a real URL is substituted at runtime.
*-r* ::
The path to the file that contains missing variable information for sets of input data files that share common missing variables. The file will be created if it doesn't exist and the result may be used in subsequent invocations of _get_dmrpp_ (using `-r`) to identify the missing variable file.


==== AWS Integration ====
The _get_dmrpp_ application supports both S3 hosted granules as inputs, and uploading generated {DMRpp} files to an S3 bucket.

*S3 Hosted granules are supported by default* ::
When the `get_dmrpp` application sees that the name of the input file is an S3 URL it will check to see if the AWS CLI is configured and if so `get_dmrpp` will attempt retrieve the granule and make a {DMRpp} utilizing whatever other options have been chosen. **For example:**

	get_dmrpp -b `pwd` s3://bucket_name/granule_object_id


*-U* ::
The `-U` command line parameter for `get_dmrpp` instructs `get_dmrpp` application to upload the generated {DMRpp} file to S3, but only when the following conditions are met:
- The name of the input file is an S3 URL.
- The `AWS CLI` has been configured with credentials that provide `r+w` permissions for the bucket referenced in the input file S3 URL.
- The `-U` option has been specified.
If all three of the above are true then `get_dmrpp` will copy the retrieve the granule, create a {DMRpp} file from the granule, and copy the resulting {DMRpp} file (as defined by the `-o` option) to the source S3 bucket using the well known NGAP sidecar file naming convention: *s3://bucket_name/granule_object_id.dmrpp*.  For example:

	get_dmrpp -U -o foo -b `pwd` s3://bucket_name/granule_object_id


=== _HDF5_handler_ Configuration ===

Because _get_dmrpp_ uses the _HDF5_handler_ software to build the {DMRpp} the software must inject the _HDF5_handler_'s configuration.

The default configuration is large, but any valued may be altered at runtime.


Here are some of the commonly manipulated configuration parameters with their default values:

----------------------------------
 H5.EnableCF=true
 H5.EnableDMR64bitInt=true
 H5.DefaultHandleDimension=true
 H5.KeepVarLeadingUnderscore=false
 H5.EnableCheckNameClashing=true
 H5.EnableAddPathAttrs=true
 H5.EnableDropLongString=true
 H5.DisableStructMetaAttr=true
 H5.EnableFillValueCheck=true
 H5.CheckIgnoreObj=false
----------------------------------

// NOTE: Mikejmnez. It states here that H5.EnableCF is `true` by default. But below it states that it is `false` by default...

==== Note to DAACs with existing Hyrax deployments. ====

If your group is already serving data with Hyrax and the data representations that are generated by your Hyrax server are satisfactory, then a careful inspection of the localized configuration, typically held in `/etc/bes/site.conf`, will help you determine what configuration state you may need to inject into _get_dmrpp_.

=== The _H5.EnableCF_ option ===

Of particular importance is the _H5.EnableCF_ option, which instructs the _get_dmrpp_ tool to produce https://cfconventions.org/[Climate Forecast convention (CF)] compatible output based on metadata found in the granule file being processed.

Changing the value of _H5.EnableCF_ from *false* to *true* will have (at least) two significant effects.

It will:

- Cause _get_dmrpp_ to attempt to make the dmr++ metadata CF compliant.
- Remove Group hierarchies (if any) in the underlying data granule by flattening the Group hierarchy into the variable names.

By default _get_dmrpp_ the _H5.EnableCF_ option is set to false:

--------------------
 H5.EnableCF = false
--------------------


There is a much more comprehensive discussion of this key feature, and others, in the https://opendap.github.io/hyrax_guide/Master_Hyrax_Guide.html#HDF5-handler[HDF5 Handler section] of the Appendix in the Hyrax Data Server Installation and Configuration Guide.

=== Missing data, the CF conventions and _HDF5_ ===

Many of the _HDF5_ files produced by NASA and others do not contain the domain coordinate data (such as latitude, longitude, time, etc.) as a collection of explicit values. Instead, information contained in the dataset metadata can be used to reproduce these values.

In order for a dataset to be Climate Forecast (CF) compatible it must contain these domain coordinate data values.

The Hyrax _HDF5_handler_ software, utilized by the _get_dmrpp_ application, can create this data from the dataset metadata.  The _get_dmrpp_ application places these generated data in a “sidecar” file for deployment with the source _HDF5/netcdf-4_ file.
